# ğŸ“– Boite Ã  outils lÃ©gistique

Cette application a Ã©tÃ© dÃ©veloppÃ©e pour simplifier l'analyse et la gestion des textes juridiques franÃ§ais et europÃ©ens en utilisant des modÃ¨les d'IA avancÃ©s.

## âš™ï¸ FonctionnalitÃ©s principales

- ğŸ“œ **Gestion des textes de loi** : Importez des textes lÃ©gislatifs franÃ§ais et europÃ©ens depuis des sources telles que Legifrance et EUR-Lex, et visualisez-les de maniÃ¨re claire et organisÃ©e.
- ğŸ¤– **Analyse assistÃ©e par IA** : Utilisez des modÃ¨les de langage comme GPT-3.5-turbo et GPT-4 pour analyser et rÃ©sumer des articles de loi complexes.
- ğŸ› ï¸ **Transposition de textes** : VÃ©rifiez la compatibilitÃ© des articles europÃ©ens avec le droit franÃ§ais et identifiez les modifications lÃ©gislatives nÃ©cessaires.
- ğŸ“¥ **TÃ©lÃ©chargement de donnÃ©es** : Exportez vos analyses sous divers formats (```.csv```, ```.json```, ```.twt```, ```.html```) pour une utilisation ultÃ©rieure.

## ğŸ› ï¸ Configuration

Le projet utilise les modÃ¨les de Langchain pour l'analyse textuelle et les embeddings. La configuration des modÃ¨les peut Ãªtre ajustÃ©e dans le fichier de configuration comme suit :

- **ModÃ¨les de langage** : GPT-3.5-turbo, GPT-4, Llama3, Gemma2, Mistral, Mixtral.
- **ModÃ¨les d'embedding** : OpenAI Text Embeddings, BGE-M3.
- **Outils de clustering et de rÃ©duction de dimensions** : KMeans, t-SNE.

## ğŸ“¥ Installation

Clonez ce dÃ©pÃ´t ...

```bash
git clone https://github.com/romainloiseau/BoiteAOutilsLegistique.git
cd BoiteAOutilsLegistique
```

... et installez les dÃ©pendances :

```bash
conda env create -f environment.yml
conda activate legaltoolbox
```

_**Note:** We use `conda`, you can download it [here](https://www.anaconda.com/download)._

ğŸ”‘ Ajoutez ensuite vos clÃ©s API dans le fichier de configuration ```configs/perso/defaults.yaml```.

### LLMs

#### Local

Cette implÃ©mentation utilise [`LangChain`](https://python.langchain.com/docs/get_started/quickstart) ainsi que [`Ollama`](https://ollama.com/) pour exÃ©cuter localement des modÃ¨les de langage open-source, et l'[API d'`OpenAI`](https://openai.com/api/) pour exÃ©cuter des modÃ¨les en ligne.

Avant d'utiliser cette implÃ©mentation via ollama, vous devrez tÃ©lÃ©charger les poids des modÃ¨les que vous utiliserez. Pour ce faire, vous pouvez utiliser la commande `ollama pull modelname`.

## ğŸš€ Usage

Pour exÃ©cuter ce implÃ©mentation localement, vous devrez lancer un serveur `Ollama` local en utilisant la commande `ollama serve` dans un terminal. Ce serveur communiquera avec votre code et votre GPU. Si vous utilisez l'API d'`OpenAI`, cela n'est pas nÃ©cessaire.

Remplissez Ã©galement le fichier `configs/perso/defaults.yaml` afin de prÃ©ciser les clÃ©s `legifrance`, `openai` et `langsmith` au besoin.

Ensuite, lancez l'application avec :

```bash
streamlit run Accueil.py
```

Pour utiliser l'application, ouvrez le lien sur lequel l'application est lancÃ©e (en principe http://localhost:8501), puis :

1. ğŸ“‚ **SÃ©lectionnez un texte** : Importez un texte lÃ©gislatif franÃ§ais ou europÃ©en ou sÃ©lectionnez-en un existant.
2. ğŸ”§ **Choisissez l'outil d'analyse** : Selon le type de texte, plusieurs outils s'offrent Ã  vous (rÃ©sumÃ©, projection, analyse d'impact, tableau de transposition).
3. âš¡ **Lancez l'analyse** : L'application analysera automatiquement le texte sÃ©lectionnÃ© et proposera des rÃ©sumÃ©s ou des suggestions de transposition.
4. ğŸ“Š **TÃ©lÃ©chargez ou visualisez les rÃ©sultats** : Visualisez les rÃ©sultats dans l'application ou exportez-les en ```.csv```, ```.json```, ```.twt``` ou ```.html```.

## âš ï¸ Avertissements

- Certaines analyses peuvent nÃ©cessiter un temps de calcul important et entraÃ®ner des coÃ»ts supplÃ©mentaires en fonction de l'API utilisÃ©e (OpenAI, Llama, etc.). Faites attention Ã  l'utilisation des LLMs pour Ã©viter des coÃ»ts inattendus.